{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "19c41f88",
      "metadata": {
        "id": "19c41f88"
      },
      "source": [
        "# Homework: Documenting Your Code + Testing Your Code\n",
        "\n",
        "## Problem 1 - Write docstrings\n",
        "\n",
        "The following functions are missing docstrings. Write Google-style docstrings for each function, including `Args`, `Returns`, and `Raises` sections where appropriate. Make sure to document default values and explain what each parameter means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2cacdf2c",
      "metadata": {
        "id": "2cacdf2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def normalize(data, method=\"zscore\"):\n",
        "    \"\"\"\n",
        "    Normalize numerical data using a specified method.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): Numeric input data to be normalized.\n",
        "        method (str, optional): Normalization method to use.\n",
        "            Options are \"zscore\" or \"minmax\".\n",
        "            Defaults to \"zscore\".\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Normalized data array.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If an unknown normalization method is provided.\n",
        "    \"\"\"\n",
        "    if method == \"zscore\":\n",
        "        return (data - np.mean(data)) / np.std(data)\n",
        "    elif method == \"minmax\":\n",
        "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "\n",
        "def weighted_mean(values, weights=None):\n",
        "    \"\"\"\n",
        "    Compute the weighted mean of input values.\n",
        "\n",
        "    Args:\n",
        "        values (array-like): Numeric input values.\n",
        "        weights (array-like, optional): Weights associated with each value.\n",
        "            If None, the arithmetic mean is returned.\n",
        "            Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: Weighted mean of the input values.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If `values` and `weights` have different lengths.\n",
        "    \"\"\"\n",
        "    if weights is None:\n",
        "        return np.mean(values)\n",
        "    if len(values) != len(weights):\n",
        "        raise ValueError(\"values and weights must have the same length\")\n",
        "\n",
        "    return np.sum(values * weights) / np.sum(weights)\n",
        "\n",
        "\n",
        "def remove_outliers(data, threshold=3.0):\n",
        "    \"\"\"\n",
        "    Remove outliers from numerical data using a standard deviation threshold.\n",
        "\n",
        "    Data points are retained if their absolute distance from the mean is less\n",
        "    than or equal to `threshold` times the standard deviation.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): One-dimensional numeric input data.\n",
        "        threshold (float, optional): Number of standard deviations from the\n",
        "            mean used to identify outliers.\n",
        "            Defaults to 3.0.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array containing only data points within the specified\n",
        "        threshold of the mean.\n",
        "    \"\"\"\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    mask = np.abs(data - mean) <= threshold * std\n",
        "    return data[mask]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(remove_outliers)"
      ],
      "metadata": {
        "id": "-2eiU6si4gJu",
        "outputId": "26ffb10d-9c59-4c66-c95a-55a6fa41a3eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-2eiU6si4gJu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function remove_outliers in module __main__:\n",
            "\n",
            "remove_outliers(data, threshold=3.0)\n",
            "    Remove outliers from numerical data using a standard deviation threshold.\n",
            "\n",
            "    Data points are retained if their absolute distance from the mean is less\n",
            "    than or equal to `threshold` times the standard deviation.\n",
            "\n",
            "    Args:\n",
            "        data (array-like): One-dimensional numeric input data.\n",
            "        threshold (float, optional): Number of standard deviations from the\n",
            "            mean used to identify outliers.\n",
            "            Defaults to 3.0.\n",
            "\n",
            "    Returns:\n",
            "        np.ndarray: Array containing only data points within the specified\n",
            "        threshold of the mean.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16fb210",
      "metadata": {
        "id": "f16fb210"
      },
      "source": [
        "## Problem 2 - Add type hints\n",
        "\n",
        "The following functions have incomplete or missing type hints. Add appropriate type hints for all parameters and return values. Use `|` syntax for union types where a parameter can accept multiple types or return `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e458a748",
      "metadata": {
        "id": "e458a748"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def clip_values(\n",
        "    arr: np.ndarray,\n",
        "    lower: float,\n",
        "    upper: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Clip array values to be within [lower, upper] range.\"\"\"\n",
        "    return np.clip(arr, lower, upper)\n",
        "\n",
        "\n",
        "def find_peaks(\n",
        "    data: list[float] | np.ndarray,\n",
        "    min_height: float | None = None\n",
        ") -> list[int] | None:\n",
        "    \"\"\"Find indices where values are local maxima above min_height.\n",
        "\n",
        "    Returns None if no peaks are found.\n",
        "    \"\"\"\n",
        "    peaks = []\n",
        "    for i in range(1, len(data) - 1):\n",
        "        if data[i] > data[i - 1] and data[i] > data[i + 1]:\n",
        "            if min_height is None or data[i] >= min_height:\n",
        "                peaks.append(i)\n",
        "    if len(peaks) == 0:\n",
        "        return None\n",
        "    return peaks\n",
        "\n",
        "\n",
        "def summarize(\n",
        "    data: np.ndarray | list[float],\n",
        "    stats: list[str]\n",
        ") -> dict[str, float]:\n",
        "    \"\"\"Calculate summary statistics for data.\n",
        "\n",
        "    Args:\n",
        "        data: Input array of numeric values.\n",
        "        stats: List of statistic names to compute.\n",
        "            Valid options: \"mean\", \"median\", \"std\", \"min\", \"max\"\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping statistic names to computed values.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    for stat in stats:\n",
        "        if stat == \"mean\": result[stat] = np.mean(data)\n",
        "        elif stat == \"median\":\n",
        "            result[stat] = np.median(data)\n",
        "        elif stat == \"std\":\n",
        "            result[stat] = np.std(data)\n",
        "        elif stat == \"min\":\n",
        "            result[stat] = np.min(data)\n",
        "        elif stat == \"max\":\n",
        "            result[stat] = np.max(data)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66a6400",
      "metadata": {
        "id": "b66a6400"
      },
      "source": [
        "## Problem 3: Identifying Test Types\n",
        "\n",
        "For each scenario below, identify whether the test being described is a **unit test**, **integration test**, or **regression test**. Briefly explain your reasoning.\n",
        "\n",
        "**(a)** You write a test that verifies `calculate_variance()` returns 0 for the input `[3.0, 3.0, 3.0]`.\n",
        "\n",
        "This is unit test as this use controlled, known case to test a single function.\n",
        "\n",
        "**(b)** After discovering that `fit_model()` crashes when given a dataset with a single row, you fix the bug and add a test with a one-row input.\n",
        "\n",
        "Regression test, as this rerun the old test when the bug got fixed.\n",
        "\n",
        "**(c)** You write a test that loads data from a CSV file, passes it through `clean_data()`, fits a model with `fit_linear_regression()`, and verifies the model's R-squared value is within an expected range.\n",
        "\n",
        "Integration test, as this test several functions jointly.\n",
        "\n",
        "**(d)** A user reports that `normalize()` returns incorrect values when all input values are negative. After fixing the issue, you add a test with input `[-5.0, -3.0, -1.0]`.\n",
        "\n",
        "Regression test, as this test the case after the bug is fixed.\n",
        "## Problem 4: Code Review - What's Wrong with These Tests?\n",
        "\n",
        "Review the following test code and identify at least **four** problems with the test design or implementation. Explain why each is problematic and suggest how to fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bb0f31e7",
      "metadata": {
        "id": "bb0f31e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def test_all_statistics():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "\n",
        "    # Test mean\n",
        "    assert np.mean(data) == 30\n",
        "\n",
        "    # Test median\n",
        "    assert np.median(data) == 30\n",
        "\n",
        "    # Test standard deviation\n",
        "    assert np.std(data) > 0\n",
        "\n",
        "    # Test min and max\n",
        "    assert np.min(data) == 10\n",
        "    assert np.max(data) == 50\n",
        "\n",
        "    # Test sum\n",
        "    assert np.sum(data) == 150\n",
        "\n",
        "def verify_variance_positive(arr):\n",
        "    var = np.var(arr)\n",
        "    assert var >= 0\n",
        "\n",
        "def test_correlation():\n",
        "    x = np.array([1.0, 2.0, 3.0])\n",
        "    y = np.array([2.0, 4.0, 6.0])\n",
        "    corr = np.corrcoef(x, y)[0, 1]\n",
        "    assert corr == 1.0\n",
        "\n",
        "results = []\n",
        "\n",
        "def test_append_result():\n",
        "    global results\n",
        "    results.append(42)\n",
        "    assert 42 in results\n",
        "\n",
        "def test_check_results():\n",
        "    assert len(results) == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. assert np.std(data) > 0 barely checks anything as many functions produce non-negative results. Suggesting using the known cases to test that.\n",
        "\n",
        "2. verify_variance_positive(arr):  should be names as test_verify_variance_positive(arr):\n",
        "\n",
        "3. global results can be problematic here, as this call the results in the global envir and when the order of test is not following what is above showed the test_check_results(): could failed. Suggesting when call the test_append_results, generate a nest list and put test_check_results inside test_append_results.\n",
        "\n",
        "4. In the correlation test, suggesting using assert np.isclose(corr, 1.0, atol=1e-12), as the output of correlation gives a float object sometimes could be very close to 1 but not exactly 1.\n"
      ],
      "metadata": {
        "id": "CGUulnHF-NIp"
      },
      "id": "CGUulnHF-NIp"
    },
    {
      "cell_type": "markdown",
      "id": "3030fab2",
      "metadata": {
        "id": "3030fab2"
      },
      "source": [
        "## Problem 5: The Flaky Test\n",
        "\n",
        "Your colleague wrote the following test for a bootstrap confidence interval function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "235ca02a",
      "metadata": {
        "id": "235ca02a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def bootstrap_ci(data, confidence=0.95, n_bootstrap=1000):\n",
        "    \"\"\"Compute bootstrap confidence interval for the mean.\"\"\"\n",
        "    means = []\n",
        "    n = len(data)\n",
        "    for _ in range(n_bootstrap):\n",
        "        sample = np.random.choice(data, size=n, replace=True)\n",
        "        means.append(np.mean(sample))\n",
        "\n",
        "    alpha = 1 - confidence\n",
        "    lower = np.percentile(means, 100 * alpha / 2)\n",
        "    upper = np.percentile(means, 100 * (1 - alpha / 2))\n",
        "    return lower, upper\n",
        "\n",
        "def test_bootstrap_ci_contains_true_mean():\n",
        "    data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "    true_mean = 5.5\n",
        "    lower, upper = bootstrap_ci(data)\n",
        "    assert lower < true_mean < upper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "bootstrap_ci(data)"
      ],
      "metadata": {
        "id": "StKQX0qcCo05",
        "outputId": "57640c83-2d77-4dab-d782-462b9de60552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "StKQX0qcCo05",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(3.8), np.float64(7.4))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860f28d3",
      "metadata": {
        "id": "860f28d3"
      },
      "source": [
        "**(a)** The test passes most of the time but occasionally fails. Explain why this test is \"flaky\" (non-deterministic).\n",
        "\n",
        "The test is non-deterministic because the bootstrap procedure is random and no seed is set, so the confidence interval changes across runs and may occasionally exclude the true mean.\n",
        "\n",
        "**(b)** Your colleague argues: \"The test is correct because a 95% confidence interval should contain the true mean 95% of the time, so occasional failures are expected.\" Is this a good argument for keeping the test as-is? Why or why not?\n",
        "\n",
        "No. Unit tests must be deterministic; probabilistic correctness does not justify flaky tests. In short, a good should pass 100% when the code is right.\n",
        "\n",
        "**(c)** Rewrite the test to be deterministic and reliable while still meaningfully testing the `bootstrap_ci` function. Your solution should: ensure reproducible results and verify that the confidence interval has reasonable properties.\n",
        "\n",
        "See next cell.\n",
        "\n",
        "\n",
        "**(d)** Propose an alternative testing strategy that could verify the 95% coverage property without making the test flaky. You don't need to implement it, but describe the approach.\n",
        "\n",
        "We can do thing like below:\n",
        "For 1000 simulated datasets:\n",
        "    compute bootstrap CI\n",
        "    check if true mean is inside\n",
        "\n",
        "coverage = proportion of successes\n",
        "assert 0.93 < coverage < 0.97\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_bootstrap_ci_reasonable():\n",
        "    np.random.seed(0)\n",
        "\n",
        "    data = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "    lower, upper = bootstrap_ci(data, confidence=0.95, n_bootstrap=1000)\n",
        "\n",
        "    # CI bounds are ordered\n",
        "    assert lower < upper\n",
        "\n",
        "    # CI contains the sample mean (deterministic check)\n",
        "    sample_mean = np.mean(data)\n",
        "    assert lower <= sample_mean <= upper\n"
      ],
      "metadata": {
        "id": "A7awOKoeD2gU"
      },
      "id": "A7awOKoeD2gU",
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}