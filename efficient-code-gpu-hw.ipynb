{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "81834325",
      "metadata": {
        "id": "81834325"
      },
      "source": [
        "# Writing Efficient Code and GPU Computing Homework\n",
        "\n",
        "Please save your solutions as a **PDF** and upload it to Canvas.\n",
        "\n",
        "## Problem 1: Profiling and Vectorization\n",
        "\n",
        "**(a)** Consider the following cProfile output from a data analysis program:\n",
        "\n",
        "```\n",
        "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
        "     5000    8.234    0.002    8.234    0.002 analysis.py:12(compute_distances)\n",
        "     5000    0.089    0.000    0.089    0.000 analysis.py:28(normalize_vector)\n",
        "  2500000    1.456    0.000    1.456    0.000 analysis.py:35(squared_diff)\n",
        "        1    0.002    0.002    9.781    9.781 analysis.py:50(main)\n",
        "```\n",
        "\n",
        "Which function should you optimize first? Explain your reasoning based on the profiling data. What percentage of the total runtime does this function account for?\n",
        "\n",
        "We should optimize the compute_distances first, as which has the longest run time per call. The percentage of total time it takes 8.234/9.781 = 84.2%\n",
        "\n",
        "**(b)** The following function computes weighted squared differences between two arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9b6ed3c6",
      "metadata": {
        "id": "9b6ed3c6"
      },
      "outputs": [],
      "source": [
        "def weighted_squared_diff_loop(x, y, w):\n",
        "    \"\"\"Compute sum of weighted squared differences using a loop.\"\"\"\n",
        "    n = len(x)\n",
        "    total = 0.0\n",
        "    for i in range(n):\n",
        "        diff = x[i] - y[i]\n",
        "        total += w[i] * diff * diff\n",
        "    return total"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab089216",
      "metadata": {
        "id": "ab089216"
      },
      "source": [
        "Write a vectorized version of this function using NumPy operations. Your function should produce the same result but without explicit Python loops. For example, `weighted_squared_diff(np.array([1, 2, 3]), np.array([0, 1, 1]), np.array([1, 2, 3]))` should return `15.0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "92ad271e",
      "metadata": {
        "id": "92ad271e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def weighted_squared_diff(x, y, w):\n",
        "    \"\"\"Compute sum of weighted squared differences using vectorization.\"\"\"\n",
        "    return np.sum(w*(x-y)**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcab2788",
      "metadata": {
        "id": "bcab2788"
      },
      "source": [
        "**(c)** Write a function that transforms an array by replacing negative values with zero and scaling all positive values by their mean. For example, given `np.array([-2, 4, -1, 6, 2])`, the positive values are `[4, 6, 2]` with mean `4.0`, so the result should be `np.array([0, 1, 0, 1.5, 0.5])`. Use boolean indexing instead of loops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e46bdcf5",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "e46bdcf5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def transform_array(arr):\n",
        "    \"\"\"Replace negatives with 0, scale positives by their mean.\"\"\"\n",
        "    result = np.zeros_like(arr, dtype=float)\n",
        "\n",
        "    pos_mask = arr > 0\n",
        "    mean_pos = arr[pos_mask].mean()\n",
        "\n",
        "    result[pos_mask] = arr[pos_mask] / mean_pos\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b201f5e",
      "metadata": {
        "id": "6b201f5e"
      },
      "source": [
        "## Problem 2: Parallelization and JIT Compilation\n",
        "\n",
        "**(a)** The following function computes the mean of a bootstrap sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dc3d71e0",
      "metadata": {
        "id": "dc3d71e0"
      },
      "outputs": [],
      "source": [
        "def compute_bootstrap_mean(args):\n",
        "    \"\"\"Compute mean of a bootstrap sample.\"\"\"\n",
        "    data, seed = args\n",
        "    rng = np.random.RandomState(seed)\n",
        "    sample = rng.choice(data, size=len(data), replace=True)\n",
        "    return np.mean(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42e9db7",
      "metadata": {
        "id": "f42e9db7"
      },
      "source": [
        "Write a function that uses `multiprocessing.Pool` to compute `n_bootstrap` bootstrap means in parallel. Each bootstrap iteration should receive a unique seed to ensure different random samples. Return a list of the bootstrap means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "74f00419",
      "metadata": {
        "id": "74f00419"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "\n",
        "\n",
        "def compute_bootstrap_mean(args):\n",
        "    \"\"\"Compute mean of a bootstrap sample.\"\"\"\n",
        "    data, seed = args\n",
        "    rng = np.random.RandomState(seed)\n",
        "    sample = rng.choice(data, size=len(data), replace=True)\n",
        "    return np.mean(sample)\n",
        "\n",
        "\n",
        "def parallel_bootstrap(data, n_bootstrap, n_workers=4):\n",
        "    \"\"\"Compute bootstrap means in parallel.\"\"\"\n",
        "    args_list = [(data, seed) for seed in range(n_bootstrap)]\n",
        "    with mp.Pool(processes=n_workers) as pool:\n",
        "        results = pool.map(compute_bootstrap_mean, args_list)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883234d6",
      "metadata": {
        "id": "883234d6"
      },
      "source": [
        "**(b)** Write a Numba-optimized function that computes the running maximum of an array. For each position `i`, the output should contain the maximum of all elements from index 0 to `i` (inclusive). For example, `running_max(np.array([3, 1, 4, 1, 5, 9, 2, 6]))` should return `np.array([3, 3, 4, 4, 5, 9, 9, 9])`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ce3f9fd4",
      "metadata": {
        "id": "ce3f9fd4"
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@njit\n",
        "def running_max(arr):\n",
        "    \"\"\"Compute running maximum of array.\"\"\"\n",
        "    n = len(arr)\n",
        "    if n == 0:\n",
        "        return arr.copy()\n",
        "\n",
        "    result = np.empty(n, dtype=arr.dtype)\n",
        "\n",
        "    current_max = arr[0]\n",
        "    result[0] = current_max\n",
        "\n",
        "    for i in range(1, n):\n",
        "        if arr[i] > current_max:\n",
        "            current_max = arr[i]\n",
        "        result[i] = current_max\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba135006",
      "metadata": {
        "id": "ba135006"
      },
      "source": [
        "**(c)** The following Numba function attempts to filter an array to keep only positive values, but it fails to compile. Explain why it fails and provide a corrected version that compiles successfully with `@njit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e89816",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "83e89816"
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@njit\n",
        "def filter_positive_broken(arr):\n",
        "    \"\"\"Return array containing only positive values (BROKEN).\"\"\"\n",
        "    count = 0\n",
        "    for x in arr:\n",
        "        if x > 0:\n",
        "            count += 1\n",
        "    result = np.empty(count, dtype=arr.dtype)\n",
        "\n",
        "    idx = 0\n",
        "    for x in arr:\n",
        "        if x > 0:\n",
        "            result[idx] = x\n",
        "            idx += 1\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous code failed to compile as the it cannot infer the type of empty python list."
      ],
      "metadata": {
        "id": "9DKNwqt9tnBW"
      },
      "id": "9DKNwqt9tnBW"
    },
    {
      "cell_type": "markdown",
      "id": "94f21d7f",
      "metadata": {
        "id": "94f21d7f"
      },
      "source": [
        "## Problem 3: GPU Computing Fundamentals\n",
        "\n",
        "**(a)** For each of the following computational tasks, state whether it would benefit from GPU acceleration and explain why or why not.\n",
        "\n",
        "1. Computing the mean of 500 numbers\n",
        "No. Transferring data to and from the GPU would dominate the runtime.\n",
        "\n",
        "2. Multiplying two 5000x5000 matrices\n",
        "Yes. Matrix multiplication is highly parallelizable and computationally intensive.\n",
        "\n",
        "3. Reading a 10GB CSV file from disk\n",
        "No. This is not related to computation method.\n",
        "\n",
        "4. Running 1 million independent Monte Carlo simulations\n",
        "Yes. This could be highly parallelizable when using GPU.\n",
        "\n",
        "5. Computing Fibonacci numbers recursively\n",
        "No. Recursive Fibonacci computation has strong data dependencies and poor parallelism.\n",
        "\n",
        "**(b)** The following code runs slowly despite using GPU. Identify the performance problem and rewrite the code to fix it. The goal is to compute the sum of squares for 1000 different arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bef6c717",
      "metadata": {
        "id": "bef6c717",
        "outputId": "9266a54b-19c1-4372-9d05-575209aeab55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 10005309.023272444\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "\n",
        "# results = []\n",
        "# for i in range(1000):\n",
        "    # data = np.random.randn(10000)  # Generate on CPU\n",
        "    # gpu_data = cp.asarray(data)    # Transfer to GPU\n",
        "    # result = cp.sum(gpu_data ** 2) # Compute on GPU\n",
        "    # results.append(result.get())   # Transfer back to CPU\n",
        "##The issue is that the data been transfered too often between CPU and GPU\n",
        "\n",
        "##reivsed code\n",
        "gpu_data = cp.random.randn(1000, 10000)\n",
        "results = cp.sum(gpu_data ** 2, axis=1)\n",
        "\n",
        "# Move result to CPU only once\n",
        "total = cp.sum(results).get()\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Total: {total}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae78333",
      "metadata": {
        "id": "5ae78333"
      },
      "source": [
        "Write an efficient version that minimizes data transfers between CPU and GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7265175a",
      "metadata": {
        "id": "7265175a"
      },
      "source": [
        "## Problem 4: CuPy and PyTorch\n",
        "\n",
        "**(a)** Convert the following NumPy code to CuPy. The function computes z-score normalization and then the correlation matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86981b8b",
      "metadata": {
        "id": "86981b8b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def correlation_matrix_numpy(X):\n",
        "    \"\"\"Compute correlation matrix after z-score normalization.\n",
        "\n",
        "    X has shape (n_samples, n_features).\n",
        "    \"\"\"\n",
        "    # Z-score normalize each column\n",
        "    mean = np.mean(X, axis=0)\n",
        "    std = np.std(X, axis=0)\n",
        "    Z = (X - mean) / std\n",
        "\n",
        "    # Compute correlation matrix\n",
        "    n = X.shape[0]\n",
        "    corr = (Z.T @ Z) / n\n",
        "    return corr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f725bb1e",
      "metadata": {
        "id": "f725bb1e"
      },
      "source": [
        "Write the CuPy version that performs the computation on GPU and returns the result as a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad7c938",
      "metadata": {
        "id": "cad7c938"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def correlation_matrix_cupy(X):\n",
        "    \"\"\"Compute correlation matrix using CuPy (GPU).\"\"\"\n",
        "    # Move data to GPU\n",
        "    X_gpu = cp.asarray(X)\n",
        "\n",
        "    # Z-score normalize each column\n",
        "    mean = cp.mean(X_gpu, axis=0)\n",
        "    std = cp.std(X_gpu, axis=0)\n",
        "    Z = (X_gpu - mean) / std\n",
        "\n",
        "    # Compute correlation matrix\n",
        "    n = X_gpu.shape[0]\n",
        "    corr_gpu = (Z.T @ Z) / n\n",
        "\n",
        "    # Move result back to CPU\n",
        "    return cp.asnumpy(corr_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zrlVw_f5Fd1T"
      },
      "id": "zrlVw_f5Fd1T"
    },
    {
      "cell_type": "markdown",
      "id": "fe047ad6",
      "metadata": {
        "id": "fe047ad6"
      },
      "source": [
        "**(b)** The following PyTorch code has a bug that causes a runtime error. Identify the error and provide the corrected code.\n",
        "\n",
        "weights is created on the CPU, while x is on the GPU, causing a device mismatch during multiplication. Below is the revised code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6fd55abb",
      "metadata": {
        "id": "6fd55abb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def process_data(numpy_array):\n",
        "    \"\"\"Process data using PyTorch on GPU.\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Convert to tensor and move to GPU\n",
        "    x = torch.from_numpy(numpy_array).to(device)\n",
        "\n",
        "    # Changed here\n",
        "    weights = torch.ones(len(numpy_array), device=device)\n",
        "\n",
        "\n",
        "    # Weighted sum\n",
        "    result = torch.sum(x * weights)\n",
        "\n",
        "    return result.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "870e56d4",
      "metadata": {
        "id": "870e56d4"
      },
      "source": [
        "**(c)** Explain why the following GPU timing code gives incorrect measurements. Then provide corrected code that accurately measures GPU computation time.\n",
        "\n",
        "The timing is incorrect because GPU operations are asynchronous and the code does not synchronize the GPU before stopping the timer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4bcdf793",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "4bcdf793",
        "outputId": "8675990e-eb18-4df8-89da-16e43adcab6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 88.78 ms\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "device = torch.device('cuda')\n",
        "a = torch.randn(5000, 5000, device=device)\n",
        "b = torch.randn(5000, 5000, device=device)\n",
        "\n",
        "start = time.perf_counter()\n",
        "c = torch.mm(a, b)\n",
        "torch.cuda.synchronize()   # Wait for GPU to finish\n",
        "elapsed = time.perf_counter() - start\n",
        "print(f\"Time: {elapsed*1000:.2f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb007cff",
      "metadata": {
        "id": "bb007cff"
      },
      "source": [
        "## Problem 5: Performance Comparison\n",
        "\n",
        "**(a)** In extreme value statistics, we often need to estimate the probability that the maximum of n independent standard normal random variables exceeds a threshold t. This can be done via Monte Carlo simulation: generate n normal values, take the maximum, and check if it exceeds t. Repeat this many times and compute the proportion that exceed t.\n",
        "\n",
        "Implement two versions of this simulation:\n",
        "\n",
        "1. A Numba-optimized CPU version using `@njit`\n",
        "2. A CuPy GPU version using vectorized operations\n",
        "\n",
        "Both functions should take parameters `n` (number of normal values per trial), `t` (threshold), and `n_simulations` (number of Monte Carlo trials), and return the estimated probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "518b5f29",
      "metadata": {
        "id": "518b5f29"
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "\n",
        "@njit\n",
        "def estimate_prob_numba(n, t, n_simulations):\n",
        "    \"\"\"Estimate P(max of n normals > t) using Numba.\"\"\"\n",
        "    count = 0\n",
        "\n",
        "    for _ in range(n_simulations):\n",
        "        # Initialize max with first sample (no hard-coded value)\n",
        "        max_val = np.random.randn()\n",
        "\n",
        "        for _ in range(1, n):\n",
        "            x = np.random.randn()\n",
        "            if x > max_val:\n",
        "                max_val = x\n",
        "\n",
        "        if max_val > t:\n",
        "            count += 1\n",
        "\n",
        "    return count / n_simulations\n",
        "\n",
        "\n",
        "def estimate_prob_cupy(n, t, n_simulations):\n",
        "    \"\"\"Estimate P(max of n normals > t) using CuPy.\"\"\"\n",
        "    # Generate all samples on GPU\n",
        "    samples = cp.random.randn(n_simulations, n)\n",
        "\n",
        "    # Max per simulation\n",
        "    max_vals = cp.max(samples, axis=1)\n",
        "\n",
        "    # Compute probability\n",
        "    prob = cp.mean(max_vals > t)\n",
        "\n",
        "    # Return scalar to CPU\n",
        "    return float(prob.get())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59b134e3",
      "metadata": {
        "id": "59b134e3"
      },
      "source": [
        "**(b)** Design an experiment to find the \"crossover point\" where the GPU version becomes faster than the CPU version. Your experiment should vary the problem size (e.g., `n_simulations`) and measure execution time for both implementations. Describe what factors affect where this crossover occurs and what values you would test.\n",
        "\n",
        "Fix n and t, and vary n_simulations over a wide range (e.g., 10^3 to 10^8). For each value, measure the runtime of the Numba CPU version and the CuPy GPU version. The crossover point is the smallest n_simulations at which the GPU runtime becomes consistently lower than the CPU runtime, reflecting when GPU parallelism outweighs its overhead.\n",
        "\n",
        "\n",
        "\n",
        "**(c)** Suppose you need to run a very large simulation with `n_simulations = 100_000_000` but your GPU only has 8GB of memory. The naive CuPy implementation would require generating a matrix of shape `(n_simulations, n)` which may not fit in memory. Write a batched version that processes the simulations in chunks to stay within memory limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f51590a",
      "metadata": {
        "id": "3f51590a"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "\n",
        "\n",
        "def estimate_prob_cupy_batched(n, t, n_simulations, batch_size): ##need to clear the batch size\n",
        "    \"\"\"Estimate P(max of n normals > t) using CuPy with batching.\"\"\"\n",
        "    exceed_count = 0\n",
        "    remaining = n_simulations\n",
        "\n",
        "    while remaining > 0:\n",
        "        current_batch = min(batch_size, remaining)\n",
        "\n",
        "        # Generate batch on GPU\n",
        "        samples = cp.random.randn(current_batch, n)\n",
        "\n",
        "        # Compute max per simulation\n",
        "        max_vals = cp.max(samples, axis=1)\n",
        "\n",
        "        # Count exceedances\n",
        "        exceed_count += int(cp.sum(max_vals > t).get())\n",
        "\n",
        "        remaining -= current_batch\n",
        "\n",
        "    return exceed_count / n_simulations"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}